version: "3.9"

services:
  # ── Voice Agent API ────────────────────────────────────────────────────────
  voice-agent:
    build:
      context: ../../
      dockerfile: infra/docker/Dockerfile
    container_name: voice-agent
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}
      - REDIS_URL=redis://redis:6379
      - FAISS_INDEX_PATH=/app/data/faiss_index
      - DOCUMENTS_PATH=/app/data/documents
      - DEBUG=${DEBUG:-false}
      - TTS_VOICE=${TTS_VOICE:-en-US-AriaNeural}
      - WHISPER_MODEL=${WHISPER_MODEL:-base.en}
      - WHISPER_DEVICE=cpu
    volumes:
      - voice_data:/app/data
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - voice-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  # ── Redis ──────────────────────────────────────────────────────────────────
  redis:
    image: redis:7-alpine
    container_name: voice-redis
    restart: unless-stopped
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - voice-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ── Ollama ─────────────────────────────────────────────────────────────────
  ollama:
    image: ollama/ollama:latest
    container_name: voice-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
      - ../../infra/ollama/ollama-init.sh:/init.sh:ro
    networks:
      - voice-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 15s
      retries: 10
      start_period: 120s
    # Uncomment for GPU support:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # ── Nginx ─────────────────────────────────────────────────────────────────
  nginx:
    image: nginx:alpine
    container_name: voice-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      # Uncomment for HTTPS:
      # - "443:443"
    volumes:
      - ../../infra/nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      # - ./certs:/etc/nginx/certs:ro  # for HTTPS
    depends_on:
      - voice-agent
    networks:
      - voice-net

  # ── Model Initializer (runs once, then exits) ──────────────────────────────
  ollama-init:
    image: curlimages/curl:latest
    container_name: voice-ollama-init
    restart: "no"
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "
      echo 'Waiting for Ollama...';
      until curl -sf http://ollama:11434/api/tags; do sleep 5; done;
      echo 'Pulling ${OLLAMA_MODEL:-llama3.2}...';
      curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"${OLLAMA_MODEL:-llama3.2}\"}';
      echo 'Pulling ${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}...';
      curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}\"}';
      echo 'Models ready!';
      "
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - voice-net

volumes:
  voice_data:
  redis_data:
  ollama_data:

networks:
  voice-net:
    driver: bridge
